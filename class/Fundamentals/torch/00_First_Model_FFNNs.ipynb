{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/Fundamentals/First_Model.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/Fundamentals/First_Model.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
    "</table>"
   ],
   "id": "f2a00ced472851ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load and preprocess dataset",
   "id": "a0819ee8aa36aab4"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:56:18.573863Z",
     "start_time": "2025-04-24T09:56:14.529760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tarfile import data_filter\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Data\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T09:56:20.756554Z",
     "start_time": "2025-04-24T09:56:18.580906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ],
   "id": "8515642b9d29982c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pytorch Model",
   "id": "a9b83d235209a24a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:16:51.078423Z",
     "start_time": "2025-04-21T12:16:51.076344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Model\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ],
   "id": "258f61b222a74331",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:16:51.089920Z",
     "start_time": "2025-04-21T12:16:51.087995Z"
    }
   },
   "cell_type": "code",
   "source": "model = MLP()",
   "id": "fce91d412f18ffb8",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:16:51.100499Z",
     "start_time": "2025-04-21T12:16:51.098793Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "c35d3791c43b9889",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "c9e2ce37fadb9bda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:16:51.113142Z",
     "start_time": "2025-04-21T12:16:51.111492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Training setup\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 10\n",
    "print_every = 1  # Print loss every 'print_every' epochs"
   ],
   "id": "1961153d295c34c1",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:40:50.708928Z",
     "start_time": "2025-04-21T12:40:50.698554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Training loop\n",
    "model.train()\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    \n",
    "    loss = loss_fn(outputs, y_train_tensor)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        acc = (outputs.argmax(1) == y_train_tensor).float().mean()\n",
    "        print(f\"Epoch {epoch} | Loss: {loss.item():.4f} | Train Acc: {acc:.4f}\")"
   ],
   "id": "6c6a765e9ee83a8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.3842 | Train Acc: 0.8462\n",
      "Epoch 1 | Loss: 0.3682 | Train Acc: 0.8487\n",
      "Epoch 2 | Loss: 0.3541 | Train Acc: 0.8475\n",
      "Epoch 3 | Loss: 0.3419 | Train Acc: 0.8462\n",
      "Epoch 4 | Loss: 0.3314 | Train Acc: 0.8475\n",
      "Epoch 5 | Loss: 0.3225 | Train Acc: 0.8475\n",
      "Epoch 6 | Loss: 0.3149 | Train Acc: 0.8512\n",
      "Epoch 7 | Loss: 0.3087 | Train Acc: 0.8512\n",
      "Epoch 8 | Loss: 0.3035 | Train Acc: 0.8575\n",
      "Epoch 9 | Loss: 0.2992 | Train Acc: 0.8575\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "d921fc69821bbba4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:40:51.635471Z",
     "start_time": "2025-04-21T12:40:51.633108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Evaluation\n",
    "model.eval()"
   ],
   "id": "166ea928049dc5a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:40:52.115476Z",
     "start_time": "2025-04-21T12:40:52.112746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_preds = test_outputs.argmax(1)\n",
    "    test_acc = (test_preds == y_test_tensor).float().mean()\n",
    "    print(f\"\\nTest Accuracy: {test_acc:.4f}\")"
   ],
   "id": "febd405e82ac1d39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.8400\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:40:54.522037Z",
     "start_time": "2025-04-21T12:40:54.519865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hist = {\n",
    "    'epoch': list(range(epochs)),\n",
    "    'loss': losses,\n",
    "}"
   ],
   "id": "f71a0b03041978c5",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:41:06.643367Z",
     "start_time": "2025-04-21T12:41:06.640603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_loss_accuracy_evolution(hist):\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Sparse Categorical Crossentropy')\n",
    "    ax1.plot(hist['epoch'], hist['loss'], label='Train Error')\n",
    "    ax1.grid()\n",
    "    ax1.legend()\n"
   ],
   "id": "d324de7dc30be6b4",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b15c9b8e820d7a93"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Practice.\n",
    "\n",
    "- Create a function that receives the number of neurons in the hidden layer and returns a model.\n",
    "\n",
    "- Create a function that computes the loss and accuracy of the model in a given subset of the dataset.\n",
    "\n",
    "- Change the number of neurons in the hidden layer to 32 and 64. What happens with the accuracy ?\n",
    "\n",
    "- Split the dataset in training and validation and plot the accuracy of both datasets\n",
    "\n",
    "- Match the same plot as with the Keras implementation using PyTorch. \n",
    "\n"
   ],
   "id": "3457b88a1aa40eb2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:47:54.115263Z",
     "start_time": "2025-04-21T12:47:54.113303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create models with different number of neurons\n",
    "def create_model(n_neurons):\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(2, n_neurons),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(n_neurons, 2)\n",
    "    )\n",
    "    return model"
   ],
   "id": "be9be93aae83f1b0",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:48:00.397681Z",
     "start_time": "2025-04-21T12:48:00.395840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute loss and accuracy on a given dataset\n",
    "def compute_loss_and_accuracy(model, X_tensor, y_tensor):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_tensor)\n",
    "        loss = loss_fn(outputs, y_tensor)\n",
    "        acc = (outputs.argmax(1) == y_tensor).float().mean()\n",
    "    return loss.item(), acc.item()"
   ],
   "id": "6aaf02f6871e1d8",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Split the dataset into training and validation",
   "id": "62d9585a6d39e64a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
