{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prospective-memorabilia",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/NLP/Embedding_layer.ipynb\">\n",
    "        <img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/NLP/Embedding_layer.ipynb\">\n",
    "        <img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-alfred",
   "metadata": {
    "id": "environmental-alfred"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-nylon",
   "metadata": {
    "id": "shaped-nylon"
   },
   "source": [
    "## Embedding layer\n",
    "\n",
    "Take a look at the documentation of the [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n",
    "\n",
    "The Embedding layer can be understood as a lookup table that maps from integer indices  to dense vectors (their embeddings). \n",
    "\n",
    "```python\n",
    "tf.keras.layers.Embedding(\n",
    "    input_dim, output_dim, input_length=None\n",
    ")\n",
    "```\n",
    "\n",
    "- **input_dim**\tInteger. Number of different categories (size of the vocabulary, number of films..) , i.e. maximum integer index + 1.\n",
    "- **output_dim** Integer. Dimension of the dense embedding.\n",
    "- **input_length** Length of input sequences, It is not necessary if you are not using sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-attraction",
   "metadata": {
    "id": "understanding-attraction"
   },
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(input_dim=100, output_dim=5, input_length=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-solid",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prescribed-solid",
    "outputId": "d6493243-2f2b-4305-8b6c-740c2bd296be"
   },
   "outputs": [],
   "source": [
    "vector_ind_0 = embedding_layer(tf.constant([0]))\n",
    "vector_ind_1 = embedding_layer(tf.constant([1]))\n",
    "vector_ind_2 = embedding_layer(tf.constant([2]))\n",
    "\n",
    "print(vector_ind_0.shape)\n",
    "print('Embedding of entity with index 0: ', vector_ind_0.numpy().flatten())\n",
    "print('Embedding of entity with index 1: ', vector_ind_1.numpy().flatten())\n",
    "print('Embedding of entity with index 2: ', vector_ind_2.numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-minnesota",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "surgical-minnesota",
    "outputId": "9cbc9688-1284-43ac-d592-e52f9108d60e"
   },
   "outputs": [],
   "source": [
    "input_sequence = [0, 1, 2, 1]\n",
    "print('input sequence', input_sequence)\n",
    "sequence = embedding_layer(tf.constant(input_sequence))\n",
    "print('sequence embeddings shape', sequence.shape)\n",
    "print('sequence embeddings', sequence.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-winning",
   "metadata": {
    "id": "authorized-winning"
   },
   "source": [
    "# Applications: Recommender System\n",
    "\n",
    "We are going too use the [MovieLens 100K dataset](https://grouplens.org/datasets/movielens/100k/). We can create model to recommend movies for a given user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "\n",
    "# Download & extract, saving the file with its original name so that .with_suffix('') gives the right folder\n",
    "zip_path = tf.keras.utils.get_file(\n",
    "    fname=os.path.basename(dataset_url),   # 'ml-latest-small.zip'\n",
    "    origin=dataset_url,\n",
    "    extract=True\n",
    ")\n",
    "data_dir = pathlib.Path(zip_path).with_suffix('')  # -> .../ml-latest-small\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-journal",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "paperback-journal",
    "outputId": "d5d9a732-d7ff-41b6-a225-39b28cac4907"
   },
   "outputs": [],
   "source": [
    "ratings_file = data_dir / \"ratings.csv\"\n",
    "df_ratings = pd.read_csv(ratings_file)\n",
    "df_ratings = sklearn.utils.shuffle(df_ratings)\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-venue",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "promotional-venue",
    "outputId": "e3737465-d8d9-49e8-8d24-855527d8364f"
   },
   "outputs": [],
   "source": [
    "##Â ratings  \n",
    "from collections import Counter\n",
    "print(Counter(df_ratings['rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-bishop",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "placed-bishop",
    "outputId": "d7a48ce8-0a4e-465c-97f5-8d23446df7ea"
   },
   "outputs": [],
   "source": [
    "# Create a user index\n",
    "user_ids = sorted(list(df_ratings[\"userId\"].unique()))\n",
    "user2index = {u: ind for ind, u in enumerate(user_ids)}\n",
    "index2user = {ind: u for u, ind in user2index.items()}\n",
    "print(list(user2index.items())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-reproduction",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lightweight-reproduction",
    "outputId": "c6a8916b-bd76-41ca-e3e1-f98df0681cc3"
   },
   "outputs": [],
   "source": [
    "# Create a movie index\n",
    "movie_ids = sorted(list(df_ratings[\"movieId\"].unique()))\n",
    "movie2index = {m: ind for ind, m in enumerate(movie_ids)}\n",
    "index2movie = {ind: m for m, ind in movie2index.items()}\n",
    "print(list(movie2index.items())[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-richards",
   "metadata": {
    "id": "clinical-richards"
   },
   "outputs": [],
   "source": [
    "df_ratings[\"user\"] = df_ratings[\"userId\"].apply(lambda user_id: user2index[user_id])\n",
    "df_ratings[\"movie\"] = df_ratings[\"movieId\"].apply(lambda movie_id: movie2index[movie_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-boating",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "located-boating",
    "outputId": "dfc6fe66-f41d-4e26-8952-a76e9db3da70"
   },
   "outputs": [],
   "source": [
    "num_users, num_movies = (len(user2index), len(movie2index))\n",
    "print(\"Number of users: {0} \\nNumber of Movies: {1}\".format(\n",
    "    num_users, num_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-knowing",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "legislative-knowing",
    "outputId": "84317600-6819-44a7-c085-4caa0f85c971"
   },
   "outputs": [],
   "source": [
    "movies_file = data_dir / \"movies.csv\"\n",
    "df_movies = pd.read_csv(movies_file)\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-greensboro",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "silent-greensboro",
    "outputId": "72f3fffc-d942-4bda-d68e-e9508804d423"
   },
   "outputs": [],
   "source": [
    "movie2title_genres = {}\n",
    "for _, row in df_movies.iterrows():\n",
    "    movie_id = row['movieId']\n",
    "    if movie_id not in movie2index:\n",
    "        continue\n",
    "    movie = movie2index[movie_id]\n",
    "    movie2title_genres[movie] = (row['title'], row['genres'])\n",
    "print(list(movie2title_genres.items())[:3])\n",
    "print(list(movie2title_genres.items())[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-rates",
   "metadata": {
    "id": "younger-rates"
   },
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-interaction",
   "metadata": {
    "id": "thrown-interaction"
   },
   "outputs": [],
   "source": [
    "embedding_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-decimal",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "proprietary-decimal",
    "outputId": "68935e7a-e71f-42e7-e991-c9d49ac825c9"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(2, ), name='user_input')\n",
    "\n",
    "## user embeddings\n",
    "user_input = inputs[:, 0]\n",
    "user_embedding = layers.Embedding(num_users,\n",
    "                                  embedding_size,\n",
    "                                  name='user_embedding')(user_input)\n",
    "\n",
    "## movie embeddings\n",
    "movie_input = inputs[:, 1]\n",
    "movie_embedding = layers.Embedding(num_movies,\n",
    "                                   embedding_size,\n",
    "                                   name='movie_embedding')(movie_input)\n",
    "\n",
    "## Concat embeddings\n",
    "concat = layers.concatenate([user_embedding, movie_embedding], axis=1)\n",
    "\n",
    "## Predict Rating\n",
    "layer_1 = layers.Dense(128, activation=\"relu\", name='layer_1')(concat)\n",
    "\n",
    "## Predict rating\n",
    "outputs = layers.Dense(1, activation='relu', name='output')(layer_1)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='movie')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-karma",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "short-karma",
    "outputId": "9b3ca9da-055c-416c-8b83-9ce4f84582d2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-degree",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "julian-degree",
    "outputId": "438392ed-161c-4ec3-bf2c-ce2927c656c5"
   },
   "outputs": [],
   "source": [
    "#df = df.sample(frac=1, random_state=42)\n",
    "x = df_ratings[[\"user\", \"movie\"]].values\n",
    "# Normalize the targets between 0 and 1\n",
    "y = df_ratings[\"rating\"].values  #/ 5.0 \n",
    "\n",
    "model.compile(\n",
    "    loss='mse', optimizer='adam'\n",
    ")\n",
    "history = model.fit(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    batch_size=64,\n",
    "    epochs=4,\n",
    "    verbose=1,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ly in enumerate(model.layers):\n",
    "    print(i, ly.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins import projector\n",
    "import os\n",
    "# Set up a logs directory, so Tensorboard knows where to look for files\n",
    "log_dir = './logs/mov/'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Save Labels separately on a line-by-line manner.\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
    "    for i, (t,g) in movie2title_genres.items():\n",
    "        f.write(\"{}\\n\".format(t))\n",
    "    \n",
    "\n",
    "weights = tf.Variable(model.layers[4].get_weights()[0])\n",
    "# Create a checkpoint from embedding, the filename and key are\n",
    "# name of the tensor.\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "# Set up config\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-universe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./logs/mov/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-curtis",
   "metadata": {
    "id": "fluid-curtis"
   },
   "source": [
    "### Show recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-tribe",
   "metadata": {
    "id": "orange-tribe"
   },
   "outputs": [],
   "source": [
    "def show_recommendations(user,\n",
    "                         model,\n",
    "                         df_ratings,\n",
    "                         movie2title_genres,\n",
    "                         n_movies=10):\n",
    "\n",
    "    total_movies = set(df_ratings['movie'].unique())\n",
    "    df_user = df_ratings[df_ratings.user == user].copy()\n",
    "    df_user = df_user.sort_values(by=\"rating\", ascending=False)\n",
    "    movies_watched = set(list(df_user['movie'].values))\n",
    "    movies_unwatched = sorted(total_movies - movies_watched)\n",
    "    top_movies = df_user[['movie', 'rating']].head(5)\n",
    "\n",
    "    print(\"Movies with high ratings from user {0}\".format(user))\n",
    "    print('-' * 50)\n",
    "    for _, row in top_movies.iterrows():\n",
    "        title, genres = movie2title_genres[row['movie']]\n",
    "        rating = row['rating']\n",
    "        print('Movie: {0} | Rating: {1}, Genres: {2}'.format(\n",
    "            title, rating, genres))\n",
    "\n",
    "    print()\n",
    "    print(\"Movies with low ratings from user {0}\".format(user))\n",
    "    print('-' * 50)\n",
    "    for _, row in df_user[['movie', 'rating']].tail(5).iterrows():\n",
    "        title, genres = movie2title_genres[row['movie']]\n",
    "        rating = row['rating']\n",
    "        print('Movie: {0} | Rating: {1}, Genres: {2}'.format(\n",
    "            title, rating, genres))\n",
    "\n",
    "    movies_array = np.array(movies_unwatched)\n",
    "    user_array = np.array([user] * len(movies_array))\n",
    "    x = np.vstack([user_array, movies_array]).T\n",
    "\n",
    "    ratings = model.predict(x).flatten()\n",
    "    movie_ratings = [(movies_array[i],ratings[i]) for i in np.argsort(-ratings)[:n_movies]]\n",
    "    \n",
    "    print()\n",
    "    print(\"Movies recommended to user {0}\".format(user))\n",
    "    print('-' * 50)\n",
    "    for movie, rating in movie_ratings:\n",
    "        title, genres = movie2title_genres[movie]\n",
    "        rating = rating #* 5\n",
    "        print('Movie: {0} | Rating pred: {1:.1f}, Genres: {2}'.format(\n",
    "            title, rating, genres))\n",
    "        \n",
    "    \n",
    "    movie_ratings = [(movies_array[i],ratings[i]) for i in np.argsort(ratings)[:3]]\n",
    "    print()\n",
    "    print(\"Movies NOT recommended to user {0}\".format(user))\n",
    "    print('-' * 50)\n",
    "    for movie, rating in movie_ratings:\n",
    "        title, genres = movie2title_genres[movie]\n",
    "        rating = rating #* 5\n",
    "        print('Movie: {0} | Rating pred: {1:.1f}, Genres: {2}'.format(\n",
    "            title, rating, genres))\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db41db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import keras\n",
    "\n",
    "def show_recommendations(\n",
    "    user: int,\n",
    "    model: keras.Model,\n",
    "    df_ratings: pd.DataFrame,\n",
    "    movie2title_genres: Dict[int, Tuple[str, str]],\n",
    "    n_movies: int = 10\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Display:\n",
    "      - Top and bottom 5 movies the user has rated\n",
    "      - Top N movie recommendations (predicted highest ratings)\n",
    "      - A few least recommended movies (predicted lowest ratings)\n",
    "    \"\"\"\n",
    "    # 1. Gather all movie IDs and this user's ratings\n",
    "    all_movies = set(df_ratings['movie'].unique())\n",
    "    user_df = (\n",
    "        df_ratings[df_ratings['user'] == user]\n",
    "        .sort_values(by='rating', ascending=False)\n",
    "    )\n",
    "\n",
    "    # 2. Split into watched vs. unwatched\n",
    "    watched = set(user_df['movie'])\n",
    "    unwatched = np.array(sorted(all_movies - watched), dtype=int)\n",
    "\n",
    "    # 3. Print user's top 5 rated movies\n",
    "    print(f\"Top 5 movies rated by user {user}\")\n",
    "    print('-' * 50)\n",
    "    for _, row in user_df.head(5).iterrows():\n",
    "        title, genres = movie2title_genres[row['movie']]\n",
    "        print(f\"Movie: {title} | Rating: {row['rating']} | Genres: {genres}\")\n",
    "\n",
    "    # 4. Print user's bottom 5 rated movies\n",
    "    print(f\"\\nBottom 5 movies rated by user {user}\")\n",
    "    print('-' * 50)\n",
    "    for _, row in user_df.tail(5).iterrows():\n",
    "        title, genres = movie2title_genres[row['movie']]\n",
    "        print(f\"Movie: {title} | Rating: {row['rating']} | Genres: {genres}\")\n",
    "\n",
    "    # 5. Build input array for the model: pairs of [user_id, movie_id]\n",
    "    user_array = np.full(shape=unwatched.shape, fill_value=user, dtype=int)\n",
    "    input_pairs = np.column_stack((user_array, unwatched))\n",
    "\n",
    "    # 6. Predict ratings for all unwatched movies\n",
    "    preds = model.predict(input_pairs).flatten()\n",
    "\n",
    "    # 7. Recommend top N movies\n",
    "    top_idxs = np.argsort(-preds)[:n_movies]\n",
    "    print(f\"\\nTop {n_movies} recommendations for user {user}\")\n",
    "    print('-' * 50)\n",
    "    for idx in top_idxs:\n",
    "        m_id = unwatched[idx]\n",
    "        title, genres = movie2title_genres[m_id]\n",
    "        print(f\"Movie: {title} | Predicted Rating: {preds[idx]:.1f} | Genres: {genres}\")\n",
    "\n",
    "    # 8. Show a few least recommended movies\n",
    "    bottom_count = min(3, len(preds))\n",
    "    bottom_idxs = np.argsort(preds)[:bottom_count]\n",
    "    print(f\"\\nMovies least recommended for user {user}\")\n",
    "    print('-' * 50)\n",
    "    for idx in bottom_idxs:\n",
    "        m_id = unwatched[idx]\n",
    "        title, genres = movie2title_genres[m_id]\n",
    "        print(f\"Movie: {title} | Predicted Rating: {preds[idx]:.1f} | Genres: {genres}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-territory",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "banned-territory",
    "outputId": "c730e3ed-87ac-4cea-a006-d11a4f01f115"
   },
   "outputs": [],
   "source": [
    "unique_users = df_ratings['user'].unique()\n",
    "user = np.random.choice(unique_users)\n",
    "show_recommendations(user, model, df_ratings, movie2title_genres, n_movies=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-adjustment",
   "metadata": {
    "id": "frank-adjustment"
   },
   "source": [
    "## Question 1: Change the embeddings dimensions and add more complexity to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-rolling",
   "metadata": {
    "id": "consolidated-rolling"
   },
   "outputs": [],
   "source": [
    "user_embedding_size = ...\n",
    "movie_embedding_size = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-rally",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "whole-rally",
    "outputId": "a5be65ba-c404-4d18-9046-3b3318338bdf"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(2, ), name='user_input')\n",
    "\n",
    "## user embeddings\n",
    "user_input = inputs[:, 0]\n",
    "user_embedding = layers.Embedding(num_users,\n",
    "                                  ...,\n",
    "                                  name='user_embedding')(user_input)\n",
    "\n",
    "## movie embeddings\n",
    "movie_input = inputs[:, 1]\n",
    "movie_embedding = layers.Embedding(num_movies,\n",
    "                                   ...,\n",
    "                                   name='movie_embedding')(movie_input)\n",
    "\n",
    "## Concat embeddings\n",
    "concat = tf.concat([user_embedding, movie_embedding], axis=1)\n",
    "\n",
    "## Predict Rating\n",
    "layer_1 = ...(concat)\n",
    "\n",
    "## Predict rating\n",
    "outputs = layers.Dense(1, activation='relu', name='output')(layer_1)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='movie')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-pendant",
   "metadata": {
    "id": "ideal-pendant"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='mse', optimizer='adam'\n",
    ")\n",
    "history = model.fit(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    batch_size=64,\n",
    "    epochs=4,\n",
    "    verbose=1,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-capability",
   "metadata": {
    "id": "published-capability"
   },
   "outputs": [],
   "source": [
    "unique_users = df_ratings['user'].unique()\n",
    "user = np.random.choice(unique_users)\n",
    "show_recommendations(user, model, df_ratings, movie2title_genres, n_movies=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-feedback",
   "metadata": {
    "id": "synthetic-feedback"
   },
   "source": [
    "## Bigger Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d50ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "\n",
    "# 1. Download & extract, saving the file with its original name so that .with_suffix('') gives the right folder\n",
    "zip_path = tf.keras.utils.get_file(\n",
    "    fname=os.path.basename(dataset_url),   # 'ml-latest-small.zip'\n",
    "    origin=dataset_url,\n",
    "    extract=True\n",
    ")\n",
    "\n",
    "# 2. The extracted folder is named exactly like the zip minus â.zipâ\n",
    "data_dir = pathlib.Path(zip_path).with_suffix('')  # -> .../ml-latest\n",
    "\n",
    "# 3. List its contents\n",
    "print(os.listdir(data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-february",
   "metadata": {
    "id": "amber-february"
   },
   "outputs": [],
   "source": [
    "movies_file = data_dir / \"movies.csv\"\n",
    "ratings_file = data_dir / \"ratings.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-mining",
   "metadata": {
    "id": "honey-mining"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-glory",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unique-glory",
    "outputId": "c3eeb856-3eba-4cf8-b1bc-97d970825a59"
   },
   "outputs": [],
   "source": [
    "def prepare_data(ratings_file, movies_file, nrows=750000):\n",
    "\n",
    "    df_ratings = pd.read_csv(ratings_file, nrows=nrows)\n",
    "    df_ratings = sklearn.utils.shuffle(df_ratings)\n",
    "\n",
    "    # Create a user index\n",
    "    user_ids = sorted(list(df_ratings[\"userId\"].unique()))\n",
    "    user2index = {u: ind for ind, u in enumerate(user_ids)}\n",
    "    index2user = {ind: u for u, ind in user2index.items()}\n",
    "    # Create a movie index\n",
    "    movie_ids = sorted(list(df_ratings[\"movieId\"].unique()))\n",
    "    movie2index = {m: ind for ind, m in enumerate(movie_ids)}\n",
    "    index2movie = {ind: m for m, ind in movie2index.items()}\n",
    "    # Change ids\n",
    "    df_ratings[\"user\"] = df_ratings[\"userId\"].apply(\n",
    "        lambda user_id: user2index[user_id])\n",
    "    df_ratings[\"movie\"] = df_ratings[\"movieId\"].apply(\n",
    "        lambda movie_id: movie2index[movie_id])\n",
    "\n",
    "    num_users, num_movies = (len(user2index), len(movie2index))\n",
    "    print(\"Number of users: {0} \\nNumber of Movies: {1}\".format(\n",
    "        num_users, num_movies))\n",
    "\n",
    "    df_movies = pd.read_csv(movies_file)\n",
    "    movie2title_genres = {}\n",
    "    for _, row in df_movies.iterrows():\n",
    "        movie_id = row['movieId']\n",
    "        if movie_id not in movie2index:\n",
    "            continue\n",
    "        movie = movie2index[movie_id]\n",
    "        movie2title_genres[movie] = (row['title'], row['genres'])\n",
    "\n",
    "    return df_ratings, movie2title_genres, num_users, num_movies\n",
    "\n",
    "df_ratings, movie2title_genres, num_users, num_movies = prepare_data(ratings_file, movies_file)\n",
    "print(len(df_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-appeal",
   "metadata": {
    "id": "senior-appeal"
   },
   "source": [
    "### Question 2: Obtain a better model and compare the number of parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-ability",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wrong-ability",
    "outputId": "aaaaaf5b-c04c-4d55-b44f-291bc5041e9f"
   },
   "outputs": [],
   "source": [
    "embedding_size = ...\n",
    "inputs = tf.keras.Input(shape=(2, ), name='user_input')\n",
    "\n",
    "## user embeddings\n",
    "user_input = inputs[:, 0]\n",
    "user_embedding = layers.Embedding(\n",
    "    num_users,\n",
    "    ...,\n",
    ")(user_input)\n",
    "\n",
    "## movie embeddings\n",
    "movie_input = inputs[:, 1]\n",
    "movie_embedding = layers.Embedding(num_movies, ...)(movie_input)\n",
    "\n",
    "## Concat embeddings\n",
    "concat = tf.concat([user_embedding, movie_embedding], axis=1)\n",
    "\n",
    "## Predict Rating\n",
    "layer_1 = ...\n",
    "## Predict rating\n",
    "outputs = layers.Dense(1, activation='relu', name='output')(...)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='movie')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-zG114uSRCka",
   "metadata": {
    "id": "-zG114uSRCka"
   },
   "outputs": [],
   "source": [
    "x = df_ratings[[\"user\", \"movie\"]].values\n",
    "# Normalize the targets between 0 and 1\n",
    "y = df_ratings[\"rating\"].values  #/ 5.0 \n",
    "model.compile(\n",
    "    loss='BinaryCrossentropy', optimizer='adam'\n",
    ")\n",
    "history = model.fit(\n",
    "    x,\n",
    "    y,\n",
    "    validation_split= 0.1,\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    batch_size=512,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jXWogzTYRNZ1",
   "metadata": {
    "id": "jXWogzTYRNZ1"
   },
   "outputs": [],
   "source": [
    "unique_users = df_ratings['user'].unique()\n",
    "user = np.random.choice(unique_users)\n",
    "show_recommendations(user, model, df_ratings, movie2title_genres, n_movies=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Embedding_layer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
