{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33aef95c",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/CNN/Introduction_to_CV_with_OpenCV.ipynb\">\n",
    "        <img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/CNN/Introduction_to_CV_with_OpenCV.ipynb\">\n",
    "        <img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad62796",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision with OpenCV in Python\n",
    "\n",
    "OpenCV (Open Source Computer Vision Library) is an open-source computer vision and machine learning software library. OpenCV was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in commercial products. It has C++, Python, and Java interfaces and supports Windows, Linux, Mac OS, iOS, and Android.\n",
    "\n",
    "**Installing OpenCV:**\n",
    "```python\n",
    "!pip install opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee52c0c",
   "metadata": {},
   "source": [
    "\n",
    "# Reading, Writing, and Displaying Images\n",
    "\n",
    "## Reading Images\n",
    "\n",
    "OpenCV allows you to read images in various formats. The most common method is using `cv2.imread()`. This function loads an image from a file and returns it as a NumPy array. If the image cannot be read (because of missing file, improper permissions, unsupported or invalid format), this function returns an empty matrix.\n",
    "\n",
    "- Syntax: `cv2.imread(path, flag)`\n",
    "- Flags:\n",
    "  - `cv2.IMREAD_COLOR` or `1`: Loads a color image. Any transparency is ignored (default).\n",
    "  - `cv2.IMREAD_GRAYSCALE` or `0`: Loads image in grayscale mode.\n",
    "  - `cv2.IMREAD_UNCHANGED` or `-1`: Loads image as such including alpha channel.\n",
    "  \n",
    "In OpenCV, when you load an image using `cv2.imread()`, the image is automatically read in BGR (Blue, Green, Red) format by default. This is different from the RGB (Red, Green, Blue) format that is commonly used in many other image processing libraries and applications. \n",
    "\n",
    "The difference between these two formats is the order of color channels:\n",
    "\n",
    "- **BGR**: The blue channel comes first, followed by green, and then red.\n",
    "- **RGB**: The red channel comes first, followed by green, and then blue.\n",
    "\n",
    "```python\n",
    "# Convert the BGR image to RGB\n",
    "image_rgb = cv2.cvtColor(image_color, cv2.COLOR_BGR2RGB)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b43623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download an image\n",
    "url = 'https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png'\n",
    "urllib.request.urlretrieve(url, \"sample.png\")\n",
    "\n",
    "\n",
    "# Path to the image\n",
    "image_path = \"sample.png\"\n",
    "\n",
    "# Read the image in color mode\n",
    "image_color = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Read the image in grayscale mode\n",
    "image_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Transform to RGB\n",
    "image_rgb = cv2.cvtColor(image_color, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))  # 1 row, 3 columns\n",
    "\n",
    "# Plot original BGR image\n",
    "axes[0].imshow(image_color)  # Convert BGR to RGB for correct color representation in matplotlib\n",
    "axes[0].set_title(\"BGR Image\")\n",
    "axes[0].axis('off')  # Hide axis\n",
    "\n",
    "# Plot grayscale image\n",
    "axes[1].imshow(image_gray, cmap='gray')  # Grayscale image\n",
    "axes[1].set_title(\"Grayscale Image\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Plot RGB image\n",
    "axes[2].imshow(image_rgb)  # RGB image\n",
    "axes[2].set_title(\"RGB Image\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c9c988",
   "metadata": {},
   "source": [
    "## Writing Images\n",
    "\n",
    "Saving an image in OpenCV is accomplished using the `cv2.imwrite()` function. It saves an image to a specified file. The image format is chosen based on the filename extension.\n",
    "\n",
    "- Syntax: `cv2.imwrite(filename, img, params)`\n",
    "- Parameters: \n",
    "  - `filename`: String representing the file name.\n",
    "  - `img`: Image to be saved.\n",
    "  - `params`: Optional parameters.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "# Save the grayscale image\n",
    "cv2.imwrite(\"path_to_save_gray_image.jpg\", image_gray)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b376323-789c-4fc0-873e-747719dcb53d",
   "metadata": {},
   "source": [
    "# Basic Image Manipulation with OpenCV\n",
    "\n",
    "In this section, we will explore basic image manipulation techniques such as resizing, rotating, and cropping images using OpenCV. These operations are fundamental in many computer vision tasks.\n",
    "\n",
    "## Resizing Images\n",
    "\n",
    "Resizing is one of the most common operations. It's used to change the dimensions of an image. In OpenCV, `cv2.resize()` function is used for this purpose.\n",
    "\n",
    "- Syntax: `cv2.resize(src, dsize[, dst[, fx[, fy[, interpolation]]]])`\n",
    "- Parameters:\n",
    "  - `src`: Input image.\n",
    "  - `dsize`: Desired size for the output image.\n",
    "  - `fx` and `fy`: Scale factors along the horizontal and vertical axes respectively.\n",
    "  - `interpolation`: Interpolation method. Common methods include `cv2.INTER_LINEAR`, `cv2.INTER_NEAREST`, `cv2.INTER_AREA`, `cv2.INTER_CUBIC`, and `cv2.INTER_LANCZOS4`. The choice of interpolation method affects the quality and processing time.\n",
    "\n",
    "Interpolation methods:\n",
    "- `cv2.INTER_LINEAR`: This is a good default choice for both upsizing and downsizing.\n",
    "- `cv2.INTER_NEAREST`: Fastest but may produce jagged edges.\n",
    "- `cv2.INTER_AREA`: Recommended for downsizing as it may produce moiré-free results.\n",
    "- `cv2.INTER_CUBIC`: Slower but more effective for upsizing.\n",
    "- `cv2.INTER_LANCZOS4`: Offers high-quality results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782011c-28ab-4062-8c36-9e4002bb644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image_1 = cv2.resize(image_rgb, (300, 300), interpolation=cv2.INTER_LINEAR)\n",
    "print(f'image shape: {resized_image_1.shape}')\n",
    "plt.imshow(resized_image_1)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3536eb-c519-41f3-9b7e-3fddfd89349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image_2 = cv2.resize(image_rgb, (0, 0), fx=0.5, fy=0.5)\n",
    "print(f'image shape: {resized_image_2.shape}')\n",
    "plt.imshow(resized_image_2)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d4899b-fec0-4a67-8146-c446513c3618",
   "metadata": {},
   "source": [
    "## Rotating Images\n",
    "\n",
    "Rotation of an image for an angle θ is achieved by the transformation matrix. In OpenCV, you use `cv2.getRotationMatrix2D` and `cv2.warpAffine` to rotate images.\n",
    "\n",
    "- `cv2.getRotationMatrix2D(center, angle, scale)` creates a 2x3 rotation matrix.\n",
    "  - `center`: Center of the rotation in the source image.\n",
    "  - `angle`: Rotation angle in degrees. Positive values mean counter-clockwise rotation.\n",
    "  - `scale`: Isotropic scale factor.\n",
    "\n",
    "- `cv2.warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]])` applies the rotation.\n",
    "  - `src`: Input image.\n",
    "  - `M`: Transformation matrix.\n",
    "  - `dsize`: Size of the output image.\n",
    "  - `flags`, `borderMode`, `borderValue`: Additional options for the transformation.\n",
    "\n",
    "To apply a transformation matrix to an image in OpenCV, particularly for rotation, we use affine transformations. An affine transformation is a linear mapping method that preserves points, straight lines, and planes. When rotating an image, each point of the original image is moved to a new location in the output image.\n",
    "\n",
    "### Formula for Rotation Transformation\n",
    "\n",
    "The transformation of a point \\((x, y)\\) in the image to a new point \\((x', y')\\) after rotation by an angle \\(\\theta\\) is given by the following formulas:\n",
    "\n",
    "\\[\n",
    "\\begin{align*}\n",
    "x' &= x \\cos \\theta - y \\sin \\theta \\\\\n",
    "y' &= x \\sin \\theta + y \\cos \\theta\n",
    "\\end{align*}\n",
    "\\]\n",
    "\n",
    "However, when rotations are performed around an arbitrary point \\((c_x, c_y)\\), we first translate the image so that the center of rotation is at the origin (0,0), rotate the image, and then translate it back.\n",
    "\n",
    "### Scale: Isotropic Scale Factor\n",
    "\n",
    "The scale factor in the rotation matrix is an isotropic scale factor. \"Isotropic\" means that the scaling is uniform in all directions. A scale factor \\(s\\) different from 1 will either enlarge (if \\(s > 1\\)) or shrink (if \\(s < 1\\)) the image. The scaling is performed with respect to the center of rotation.\n",
    "\n",
    "### Rotation Matrix\n",
    "\n",
    "The rotation matrix \\(M\\) obtained from `cv2.getRotationMatrix2D` in OpenCV is a 2x3 matrix that combines these transformations (rotation, translation, scaling):\n",
    "\n",
    "\\begin{equation}\n",
    "M = \\begin{bmatrix}\n",
    "s \\cdot \\cos \\theta & -s \\cdot \\sin \\theta & (1 - s \\cdot \\cos \\theta) \\cdot c_x + s \\cdot \\sin \\theta \\cdot c_y \\\\\n",
    "s \\cdot \\sin \\theta & s \\cdot \\cos \\theta & (1 - s \\cdot \\cos \\theta) \\cdot c_y - s \\cdot \\sin \\theta \\cdot c_x\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb21fbd-48d0-4a81-8ec8-b82a659d8e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rotation matrix\n",
    "rotation_matrix = cv2.getRotationMatrix2D((image_rgb.shape[1]/2, image_rgb.shape[0]/2), 45, 1)\n",
    "print(rotation_matrix)\n",
    "# Perform the rotation\n",
    "rotated_image = cv2.warpAffine(image_rgb, rotation_matrix, (image_rgb.shape[1], image_rgb.shape[0]))\n",
    "\n",
    "plt.imshow(rotated_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970a83b-7742-4446-84b3-dae8f40886a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider, FloatSlider\n",
    "\n",
    "def rotate_image(angle, center_x, center_y, scale):\n",
    "    rows, cols, _ = image_color.shape\n",
    "    M = cv2.getRotationMatrix2D((center_x, center_y), angle, scale)\n",
    "    rotated = cv2.warpAffine(image_color, M, (cols, rows))\n",
    "    plt.imshow(cv2.cvtColor(rotated, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "interact(rotate_image, \n",
    "         angle=IntSlider(min=-180, max=180, step=1, value=0),\n",
    "         center_x=FloatSlider(min=0, max=image_color.shape[1], step=0.1, value=image_color.shape[1]/2),\n",
    "         center_y=FloatSlider(min=0, max=image_color.shape[0], step=0.1, value=image_color.shape[0]/2),\n",
    "         scale=FloatSlider(min=0.1, max=3, step=0.1, value=1));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c11982-6e01-491d-a1b9-327723bf88d8",
   "metadata": {},
   "source": [
    "## Cropping Images\n",
    "\n",
    "Cropping involves cutting out a portion of an image. In OpenCV, this can be done by slicing the NumPy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab09ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the image\n",
    "cropped_image = image_rgb[50:250, 100:350]  # Crop from x=100, y=50 to x=300, y=200\n",
    "\n",
    "plt.imshow(cropped_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea375c7d-1366-4981-95b7-7487167c3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "# Define the crop box coordinates (x, y, width, height)\n",
    "crop_box = (100, 100, 200, 200)  # (x, y, width, height)\n",
    "\n",
    "# Create a Rectangle patch\n",
    "rect = patches.Rectangle((crop_box[0], crop_box[1]), crop_box[2], crop_box[3], linewidth=2, edgecolor='r', facecolor='none')\n",
    "\n",
    "# Plot the original image and the rectangle\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image_rgb)\n",
    "ax.add_patch(rect)\n",
    "plt.show()\n",
    "\n",
    "# Define the box to crop\n",
    "# Note: OpenCV uses the format (y, y+h, x, x+w) for cropping\n",
    "cropped_image = image_rgb[crop_box[1]:crop_box[1] + crop_box[3], crop_box[0]:crop_box[0] + crop_box[2]]\n",
    "\n",
    "# Display the cropped image\n",
    "plt.imshow(cropped_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b0f78-471b-472a-afde-45ef068068d3",
   "metadata": {},
   "source": [
    "# Image Thresholding with OpenCV\n",
    "\n",
    "Image thresholding is a simple, yet effective, way of partitioning an image into a foreground and background. This is done by selecting a threshold value, and then classifying all pixels above this threshold as belonging to the foreground (usually white) and all pixels below this threshold as belonging to the background (usually black).\n",
    "\n",
    "## Basic Thresholding\n",
    "\n",
    "The most basic form of thresholding applies a fixed level threshold to each pixel. The general form of the thresholding operation on an image \\( f(x, y) \\) can be expressed as:\n",
    "\n",
    "\\begin{equation}\n",
    " g(x, y) = \\begin{cases} \n",
    "\\text{maxVal} & \\text{if } f(x, y) > \\text{threshold} \\\\\n",
    "0 & \\text{otherwise} \n",
    "\\end{cases} \n",
    "\\end{equation}\n",
    "\n",
    "In OpenCV, this is implemented using the `cv2.threshold` function.\n",
    "\n",
    "- Syntax: `retval, dst = cv2.threshold(src, thresh, maxval, type)`\n",
    "- Parameters:\n",
    "  - `src`: Input image (grayscale).\n",
    "  - `thresh`: Threshold value.\n",
    "  - `maxval`: Maximum value to use with the binary thresholding operations.\n",
    "  - `type`: Thresholding type (e.g., `cv2.THRESH_BINARY`, `cv2.THRESH_BINARY_INV`, etc.)\n",
    "\n",
    "Example of basic thresholding:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313b10e-8f4b-4b16-9354-d3c72c616ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grayscale\n",
    "gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply basic thresholding\n",
    "ret, thresh_basic = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.imshow(thresh_basic, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea8385-981a-41bc-81fa-9cdac9f59766",
   "metadata": {},
   "source": [
    "## Adaptive Thresholding\n",
    "\n",
    "Adaptive thresholding changes the threshold value based on the image characteristics. In adaptive thresholding, the threshold value is determined for smaller regions. This leads to different threshold values for different regions of the same image, which is useful in case of varying lighting conditions across the image.\n",
    "\n",
    "OpenCV provides `cv2.adaptiveThreshold` for this purpose.\n",
    "\n",
    "- Syntax: `dst = cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C)`\n",
    "- Parameters:\n",
    "  - `maxValue`: Non-zero value assigned to the pixels for which the condition is satisfied.\n",
    "  - `adaptiveMethod`: Adaptive method decides how the threshold value is calculated (e.g., `cv2.ADAPTIVE_THRESH_MEAN_C`, `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`).\n",
    "    1. **`cv2.ADAPTIVE_THRESH_MEAN_C`:**\n",
    "       - This method calculates the mean of the `blockSize` x `blockSize` neighborhood of each pixel (excluding the pixel itself) and subtracts `C` from this mean to determine the pixel's threshold.\n",
    "       - It's useful for images with a relatively uniform brightness, where the goal is to highlight the central tendencies in local areas of the image.\n",
    "\n",
    "    2. **`cv2.ADAPTIVE_THRESH_GAUSSIAN_C`:**\n",
    "           - This method calculates the weighted sum of the `blockSize` x `blockSize` neighborhood, where the weights are a Gaussian window, and subtracts `C` from this sum to determine the pixel's threshold.\n",
    "           - It's more sophisticated and considers the spatial distribution of pixel intensities, making it more suitable for images with varying illumination conditions.\n",
    "\n",
    "  - `blockSize`: Size of a pixel neighborhood that is used to calculate a threshold value. It must be an odd number greater than 1\n",
    "    - A larger `blockSize` considers a larger area for local thresholding, which can be useful for images with more significant variations in lighting. However, it might also reduce the detail in the thresholded image.\n",
    "  - `C`: Constant subtracted from the mean or weighted mean.\n",
    "      - `C` allows fine-tuning of the thresholding. It serves as a bias in the threshold calculation.\n",
    "      - If `C` is positive, it makes the algorithm more aggressive, producing a more contrasted image by making the dark regions darker.\n",
    "      - If `C` is negative, it makes the algorithm less sensitive, which might retain more details but could also include more noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676e9ed8-5df3-4f55-be3c-7a6d6d2ef99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_thresh = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "plt.imshow(adaptive_thresh, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4697826-ac34-4ff4-8eba-e102bd0184e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, widgets\n",
    "\n",
    "def interactive_thresholding(thresh_type, threshold, block_size, C):\n",
    "    if thresh_type == 'Binary':\n",
    "        _, th = cv2.threshold(gray_image, threshold, 255, cv2.THRESH_BINARY)\n",
    "    elif thresh_type == 'Adaptive Mean':\n",
    "        th = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, block_size, C)\n",
    "    elif thresh_type == 'Adaptive Gaussian':\n",
    "        th = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, C)\n",
    "    \n",
    "    plt.imshow(th, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "interact(interactive_thresholding, \n",
    "         thresh_type=widgets.Dropdown(options=['Binary', 'Adaptive Mean', 'Adaptive Gaussian'], value='Binary', description='Threshold Type:'),\n",
    "         threshold=widgets.IntSlider(min=0, max=255, step=1, value=127, description='Threshold:'),\n",
    "         block_size=widgets.IntSlider(min=3, max=21, step=2, value=11, description='Block Size:', disabled=False),\n",
    "         C=widgets.IntSlider(min=0, max=10, value=2, description='C Value:')\n",
    "        );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8a079e-aaee-44f5-b26c-81cb0c8bffdd",
   "metadata": {},
   "source": [
    "# Question 1: Read the image of the bill in grayscale, rotate it to a vertical orientation, and apply an appropriate thresholding technique to improve the image quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d475a6c-fe6a-49d8-a241-90bac6b4f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/ezponda/intro_deep_learning/blob/main/images/bill_1.jpg?raw=true'\n",
    "image_path = \"bill_1.jpeg\"\n",
    "urllib.request.urlretrieve(url, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e19c53-69a6-4c12-8890-ebf9054ffac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image in grayscale mode\n",
    "image_gray = cv2.imread(..., cv2..)\n",
    "\n",
    "plt.imshow(image_gray, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554946a-b7ad-431d-8145-07687e15a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_matrix = cv2.getRotationMatrix2D(\n",
    "    (image_gray.shape[1]/2, image_gray.shape[0]/2), ..., 1\n",
    ")\n",
    "\n",
    "# Perform the rotation\n",
    "rotated_image = cv2.warpAffine(..., ..., (image_gray.shape[1], image_gray.shape[0]))\n",
    "\n",
    "plt.imshow(rotated_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe64cc-eac6-42d1-bb23-747247ea8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply basic thresholding to rotated_image\n",
    "# ret, img_thresh = cv2.threshold(...)\n",
    "\n",
    "# Or apply  adaptive thresholding to rotated_image\n",
    "# img_thresh = cv2.adaptiveThreshold(rotated_image, 255, ..., ..., ..., ...)\n",
    "\n",
    "plt.imshow(img_thresh, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b923e1-b6ca-46cd-b8dd-706796abb835",
   "metadata": {},
   "source": [
    "# Histogram Equalization in OpenCV\n",
    "\n",
    "Histogram equalization is a technique for adjusting image intensities to enhance contrast. It's particularly useful in images with backgrounds and foregrounds that are both bright or both dark.\n",
    "\n",
    "## Understanding Histograms in Image Processing\n",
    "\n",
    "A histogram represents the distribution of pixel intensities (whether in grayscale or color channels) in an image. It plots the number of pixels for each intensity value.\n",
    "\n",
    "### Displaying a Histogram for a Real Image\n",
    "\n",
    "First, let's see how to display a histogram for a grayscale image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a7f227-29bc-451e-b040-1495cbcbf410",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Normal_posteroanterior_%28PA%29_chest_radiograph_%28X-ray%29.jpg/560px-Normal_posteroanterior_%28PA%29_chest_radiograph_%28X-ray%29.jpg'\n",
    "image_path = \"x-ray.jpeg\"\n",
    "urllib.request.urlretrieve(url, image_path)\n",
    "\n",
    "# Load an image in grayscale\n",
    "gray_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Calculate the histogram\n",
    "hist = cv2.calcHist([gray_image], [0], None, [256], [0, 256])\n",
    "\n",
    "\n",
    "# Plot the image and its histogram\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Display the image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(gray_image, cmap='gray')\n",
    "plt.title(\"Grayscale Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the histogram\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist)\n",
    "plt.title(\"Grayscale Histogram\")\n",
    "plt.xlabel(\"Bins\")\n",
    "plt.ylabel(\"# of Pixels\")\n",
    "plt.xlim([0, 256])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e201ea6b-5a7e-49c9-a0ad-8acf0c3dc53a",
   "metadata": {},
   "source": [
    "## Histogram Equalization\n",
    "\n",
    "Histogram equalization improves the contrast of an image by stretching out the intensity range.\n",
    "\n",
    "### Concept\n",
    "\n",
    "The idea is to spread out the most frequent intensity values, i.e., to stretch the histogram horizontally on both sides, making the dark pixels darker and the bright pixels brighter. This often increases the global contrast of many images, especially when the usable data of the image is represented by close contrast values.\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "Given a grayscale image \\( I \\), histogram equalization works by first calculating the normalized histogram \\( H(v) \\) for each intensity level \\( v \\). Then, a cumulative distribution function (CDF) is computed, which is essentially a cumulative sum of the normalized histogram values:\n",
    "\n",
    "\\begin{equation}\n",
    "CDF(v) = \\sum_{i=0}^{v} H(i)\n",
    "\\end{equation}\n",
    "\n",
    "The equalized image \\( I_{eq} \\) is obtained by mapping each pixel intensity \\( v \\) in the original image to a new intensity level using the CDF:\n",
    "\n",
    "\\begin{equation}\n",
    "I_{eq}(x, y) = \\text{round} \\left( \\frac{CDF(I(x, y)) - \\text{min}(CDF)}{\\text{max}(CDF) - \\text{min}(CDF)} \\times 255 \\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a923cf6-28e2-469e-b000-145150839740",
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized_image = cv2.equalizeHist(gray_image)\n",
    "\n",
    "# Calculate histograms\n",
    "hist_original = cv2.calcHist([gray_image], [0], None, [256], [0, 256])\n",
    "hist_equalized = cv2.calcHist([equalized_image], [0], None, [256], [0, 256])\n",
    "\n",
    "# Create a 2x2 subplot\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Display the original image\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(gray_image, cmap='gray')\n",
    "plt.title(\"Original Grayscale Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the histogram for the original image\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(hist_original)\n",
    "plt.title(\"Histogram of Original Image\")\n",
    "plt.xlabel(\"Bins\")\n",
    "plt.ylabel(\"# of Pixels\")\n",
    "plt.xlim([0, 256])\n",
    "\n",
    "# Display the equalized image\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(equalized_image, cmap='gray')\n",
    "plt.title(\"Histogram Equalized Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the histogram for the equalized image\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(hist_equalized)\n",
    "plt.title(\"Histogram of Equalized Image\")\n",
    "plt.xlabel(\"Bins\")\n",
    "plt.ylabel(\"# of Pixels\")\n",
    "plt.xlim([0, 256])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d3456e-5424-4093-856d-f6b04f3e6059",
   "metadata": {},
   "source": [
    "## CLAHE: Contrast Limited Adaptive Histogram Equalization\n",
    "\n",
    "CLAHE is a variant of adaptive histogram equalization in which the image is divided into small blocks called \"tiles\" (e.g., 8x8). Then, histogram equalization is applied to each of these blocks separately. This method prevents over-amplification of noise that is typical in the standard histogram equalization technique.\n",
    "\n",
    "### Key Features of CLAHE:\n",
    "- **Local Contrast Enhancement:** Unlike standard histogram equalization, which applies a global contrast enhancement, CLAHE enhances the contrast locally.\n",
    "- **Contrast Limiting:** To prevent noise amplification, CLAHE applies contrast limiting. If any histogram bin is above the specified contrast limit, those pixels are clipped and distributed uniformly to other bins before applying histogram equalization.\n",
    "\n",
    "### Mathematical Overview:\n",
    "CLAHE operates similarly to adaptive histogram equalization but with an additional contrast limiting step. After computing the histogram for each block, the histogram is clipped at a predefined value, ensuring that the enhancement doesn’t increase the noise.\n",
    "\n",
    "### Applying CLAHE in OpenCV:\n",
    "OpenCV provides the `createCLAHE` function to apply CLAHE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32fcbf-747a-4bbc-a8a5-1ced69db7e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CLAHE object\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "# Apply CLAHE to the grayscale image\n",
    "clahe_image = clahe.apply(gray_image)\n",
    "\n",
    "# Display the original and CLAHE-enhanced image\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121), plt.imshow(gray_image, cmap='gray'), plt.title('Original Image')\n",
    "plt.subplot(122), plt.imshow(clahe_image, cmap='gray'), plt.title('CLAHE Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d754aef5-14c4-4cfd-ac46-637f94a8bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_clahe(clip_limit, tile_grid_size):\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(tile_grid_size, tile_grid_size))\n",
    "    clahe_image = clahe.apply(gray_image)\n",
    "\n",
    "    plt.imshow(clahe_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "interact(view_clahe, \n",
    "         clip_limit=widgets.FloatSlider(min=1, max=5, step=0.1, value=2),\n",
    "         tile_grid_size=widgets.IntSlider(min=1, max=16, step=1, value=8));\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
